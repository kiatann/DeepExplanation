{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eee73621",
   "metadata": {},
   "source": [
    "# Preprocessing Raw Data\n",
    "\n",
    "<p>Parts of the code that need to be checked before execution when data access is available again: \n",
    "    <ul>\n",
    "        <li> Label processor: can't drop index 63399 because you don't know what the hashed version is. \n",
    "        <li> Pre-processing average counselor reviews: check whether you can actually drop that section of the code. \n",
    "        <li> Pre-processing average counselor reviews: Figure out why gamma is 0.9\n",
    "    </ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "583607c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import label_processor\n",
    "import nltk\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import pickle\n",
    "import torch\n",
    "import tqdm\n",
    "import transformers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from label_processor import list_series_values\n",
    "from label_processor import LabelProcessorSimplified, list_series_value_counts\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50262052",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_directory = \"raw/\"\n",
    "pickle_directory = \"pickle/\"\n",
    "save_directory = \"saved/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb26426",
   "metadata": {},
   "source": [
    "### Pre-processing counselor surveys (COUNSELOR_SURVEY.tsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d15d33f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarah/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "## loads files and gets the number of raw rows to compare how many rows are empty later\n",
    "## standardizes column names to lowercase\n",
    "\n",
    "survey = pd.read_csv(raw_directory+\"SURVEY_VALUE.tsv\", sep='\\t')\n",
    "survey.columns = survey.columns.str.lower()\n",
    "lines = survey.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dbad73",
   "metadata": {},
   "outputs": [],
   "source": [
    "## processing the survey values \n",
    "## check that the values correspond correctly \n",
    "\n",
    "survey.value.replace([\"a:0:{}\",\n",
    "                      \"N;\",\n",
    "                      'a:2:{i:0;N;i:1;s:0:\";}\"',\n",
    "                      'a:3:{i:0;N;i:1;N;i:2;s:0:\";}\"',\n",
    "                      'a:1:{i:0;s:0:\";}\"',\n",
    "                      'a:1:{i:0;s:0:\";}\"',\n",
    "                      'a:1:{i:0;s:3:n/a\";}\"',\n",
    "                      'a:1:{i:0;s:3:N/A\";}\"',\n",
    "                      'a:2:{i:0;s:0:\";i:1;s:0:\"\";}\"',\n",
    "                      's:1:\" \";',\n",
    "                      's:4:\"b:0;\";',\n",
    "                      'a:1:{i:0;s:0:\"\";}',\n",
    "                      \"\"\n",
    "                     ],np.nan,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d36f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## drops empty values and checks how many lines were dropped\n",
    "\n",
    "survey = survey.dropna(subset=[\"value\"])\n",
    "lines2 = survey.shape[0]\n",
    "print(f\"{lines - lines2} lines were blank or N/A ({(lines - lines2)/lines*100:.3f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3326c4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## checks that the responses are unicode characters; this part checks for responses starting with a:\n",
    "\n",
    "chars = \"\\w\\s\\'\\\"\\d\\,\\.\\-\\/\\&\\(\\):/!?\\+\\@=-—£\\[\\]%’‘’#\\*<>”“´…\"\n",
    "giant_regex = r\"[i][:]\\d+[;][s][:]\\d+[:]\\s\\\"\\s[\\w\\s\\'\\\"\\d\\,\\.\\-\\/\\&\\(\\):/!?\\+\\@=-—£\\[\\]%’‘’#\\*<>”“´…]+\\s\\\"\\s[;]\"\n",
    "\n",
    "array_values = survey.value.dropna()\n",
    "array_values = array_values[array_values.str.contains(\"^a:\\d\",regex=True)]\n",
    "\n",
    "array_values = array_values.apply(lambda v: re.findall(giant_regex,v))\n",
    "array_values = array_values.apply(lambda v: v if len(v)>0 else np.nan)\n",
    "array_values = array_values.apply(lambda a:[i for i in a if re.match(\"\\w\",i)] if type(a) == list else a)\n",
    "\n",
    "array_values = array_values.astype(str).str.replace('i:\\d;s:\\d+:\\s\\\"\\s',\"\",regex=True)\n",
    "array_values = array_values.astype(str).str.replace('\\s\\\"\\s;', \"\", regex=True)\n",
    "\n",
    "survey[\"array_value\"] = array_values\n",
    "print(f\"failed: {array_values.isna().sum()}, or {array_values.isna().mean()*100:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c95842b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## drops the failed rows from the survey\n",
    "drop_index = array_values[array_values.isna()].index\n",
    "survey = survey.drop(drop_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c08d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "## checks the remaining values, incl. encoded responses starting with s:\n",
    "## checks that all remaining non-N/A values are strings\n",
    "\n",
    "## values that are not na and match; note that this would incl. responses starting with s:digit \n",
    "## these responses were not incl. in array_values, which only looked for values containing a:digit\n",
    "str_values = survey[~(survey.value.isna()) & survey.array_value.isna()].value\n",
    "\n",
    "## get the shape of this\n",
    "a = str_values.shape[0]\n",
    "\n",
    "## values that start with the format s:digit \n",
    "m = str_values.str.contains(\"^s:\\d+\", regex=True)\n",
    "\n",
    "## values that do not start with the format s:digit\n",
    "leftover = str_values[~m]\n",
    "\n",
    "## values that start with the format s:digit\n",
    "str_values = str_values[m]\n",
    "\n",
    "## get the shape of values that start with format s:digit\n",
    "b = str_values.shape[0]\n",
    "\n",
    "print(\"Okay, all remaining non-N/A values are strings.\" if a==b \n",
    "      else f\"Hmm... {leftover.shape[0]} values are not N/A but not recognised as strings either\" )\n",
    "\n",
    "str_values = str_values.str.replace('s:\\d+[:]\\s\\\"\\s',\"\",regex=True)\n",
    "str_values = str_values.str.replace('\\s\\\"\\s;', \"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0d89f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## checks the number of failed values \n",
    "\n",
    "survey['str_value'] = str_values\n",
    "f = ~str_values.str.match('\\w+')\n",
    "print(f\"failed: {f.sum()}, or {f.mean()*100:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78cbabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop the failed rows from the array\n",
    "to_drop = f[f==True].index\n",
    "survey = survey.drop(to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6325d2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## creates the columns for a table of answers to the survey\n",
    "\n",
    "q_ids = survey.question_id.unique()\n",
    "q_ids = [i for i in q_ids if i != 23]\n",
    "for q in q_ids.copy():\n",
    "    s = survey[survey.question_id==q]\n",
    "    a = s.str_value.isna().all()\n",
    "    b = s.array_value.isna().all()\n",
    "    \n",
    "    if a and not b:\n",
    "        vals = s.array_value\n",
    "    elif b and not a:\n",
    "        vals = s.str_value\n",
    "    else:\n",
    "        raise ValueError(q)\n",
    "    survey.loc[survey.question_id==q,q] = vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e59655",
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading survey.tsv and standardizing column name\n",
    "\n",
    "survey_conversation = pd.read_csv(raw_directory+\"SURVEY.tsv\", sep='\\t')\n",
    "survey_conversation.columns = survey_conversation.columns.str.lower()\n",
    "survey_conversation = survey_conversation.rename({\"id\":\"survey_id\"},axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d73a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## grouping by survey id and setting questions as the columns\n",
    "\n",
    "survey2 = survey.drop(['value','array_value','str_value','last_edit_time'],axis=1).set_index(['survey_id'])\n",
    "survey_conversation2 = survey_conversation.copy()\n",
    "for q in q_ids:\n",
    "    i = survey2[q].dropna().index\n",
    "    assert i.nunique() == i.shape[0]\n",
    "    survey_conversation2 = survey_conversation2.join(survey2[q].dropna(),on=\"survey_id\",how=\"left\")\n",
    "\n",
    "survey_conversation = survey_conversation2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ff8466",
   "metadata": {},
   "outputs": [],
   "source": [
    "## filling up some na values. If all columns are NA for that row, drop those. \n",
    "\n",
    "survey_conversation = survey_conversation.set_index(\"conversation_id\").drop(\"survey_id\",axis=1).dropna(how='all')\n",
    "\n",
    "survey_conversation[21].fillna(\"NA\",inplace=True)\n",
    "survey_conversation[22].fillna(\"NA\",inplace=True)\n",
    "survey_conversation[33].fillna(\"NA\",inplace=True)\n",
    "\n",
    "survey_conversation[[18,26,27,19]] = survey_conversation[[18,26,27,19]].applymap(lambda a: [] if a is np.nan else a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d284af25",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in survey_conversation.columns:\n",
    "    survey_conversation[i] = survey_conversation[i].str.replace(\"\\'\", \"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ed9d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## sanity check\n",
    "survey_conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d7fa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "## saving \n",
    "survey_conversation.to_pickle(save_directory+'counselor_survey_by_conversation.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a9a5b9",
   "metadata": {},
   "source": [
    "### Pre-processing MESSAGE_PART.tsv\n",
    "\n",
    "<p> concatenates all the tsvs into one file and drops some unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbad2bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## pickles all the message tsvs for next step\n",
    "\n",
    "num_files = max([int(re.findall(\"MESSAGE_PART_(\\d+)\",i)[0]) for i in os.listdir(raw_directory) if \"MESSAGE_PART\" in i])\n",
    "for i in trange(1, num_files + 1): \n",
    "    df = pd.read_csv(f\"{raw_directory}MESSAGE_PART_{i}.tsv\", sep='\\t')\n",
    "    df.to_pickle(pickle_directory+f\"MESSAGE_PART_{i}.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c313d435",
   "metadata": {},
   "outputs": [],
   "source": [
    "## saves all the messages in one file only \n",
    "\n",
    "num_files = max([int(re.findall(\"MESSAGE_PART_(\\d+)\",i)[0]) for i in os.listdir(raw_directory) if \"MESSAGE_PART\" in i])\n",
    "df = pd.concat([pd.read_pickle(pickle_directory+f\"MESSAGE_PART_{i}.pickle\") for i in trange(1, num_files + 1)])\n",
    "df.to_pickle(save_directory+\"raw_messages.pickle\")\n",
    "\n",
    "# kill kernel to avoid memory overflow. Redo imports + variable definition and continue from next cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885f8aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardizes column names\n",
    "# drops unnecessary columns\n",
    "\n",
    "df = pd.read_pickle(save_directory+\"raw_messages.pickle\")\n",
    "df.columns = df.columns.str.lower()\n",
    "dropped_columns = [\"salt\",\"retries\",\"delivery_error\",\"media_uri\",\"media_mimetype\"]\n",
    "df.drop(dropped_columns,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8776f0",
   "metadata": {},
   "source": [
    "### Pre-processing CONVERSATION_PARTICIPATION\n",
    "\n",
    "<p> Uses conversation_participation.tsv to set the actor_ids as texter or counselor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3e3e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"saved/raw_messages.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de59dc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "## inspect df first!!\n",
    "robot_id = df.loc[[1], 'ACTOR_ID'].iloc[0]; robot_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4b2fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading the tsv\n",
    "## standardize column names\n",
    "\n",
    "conversation_participation = pd.read_csv(raw_directory+'CONVERSATION_PARTICIPATION.tsv', sep='\\t')\n",
    "conversation_participation.columns = [i.lower() for i in conversation_participation.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d0afa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gets counselor and texter IDs\n",
    "\n",
    "counselor_ids = conversation_participation[conversation_participation['interaction'].isin(['counselor','observer'])].actor_id.unique()\n",
    "texter_ids = conversation_participation[conversation_participation['interaction'] == 'texter'].actor_id.unique()\n",
    "counselor_ids = set(counselor_ids)\n",
    "texter_ids = set(texter_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73037d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## assigns interactions i.e. whether texter or counselor\n",
    "\n",
    "df.loc[df.actor_id == robot_id, \"interaction\"] = \"bot\"\n",
    "df.loc[df.actor_id.isin(texter_ids), \"interaction\"] = \"texter\"\n",
    "df.loc[df.actor_id.isin(counselor_ids), \"interaction\"] = \"counselor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2283d64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## checks whether there are missing interactions; if none, skip next step\n",
    "if df.interaction.isna().any():\n",
    "    print(\"There are missing interactions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fe9b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "## If still necessary, use the heuristic that all conversations are started by the texter\n",
    "\n",
    "if df.interaction.isna().any():\n",
    "    first_id_per_convo = df[df.id.isin(df.groupby('conversation_id').id.first())]\n",
    "    texter_ids.update(first_id_per_convo[first_id_per_convo.interaction.isna()].actor_id)\n",
    "    df.loc[df.actor_id.isin(texter_ids), \"interaction\"] = \"texter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748759b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## saves the df with actors\n",
    "\n",
    "df.to_pickle(save_directory+'messages_with_actors.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d5d4bd",
   "metadata": {},
   "source": [
    "### Fix character weirdness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00987650",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the df again\n",
    "df = pd.read_pickle(save_directory+'messages_with_actors.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8228bb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use RoBERTa-base tokenizer to replace some unknown characters later\n",
    "\n",
    "MODEL_NAME = \"roberta-base\"\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a8d224",
   "metadata": {},
   "outputs": [],
   "source": [
    "## drops messed up messages that contain aes256\n",
    "df = df[~df.message.str.contains(\"aes256\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34891c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "## replaces emojis\n",
    "df.message = df.message.str.replace('<span class=\"?\\w+ (\\w+)\"?></span>',\"[\\\\1]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db410f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fix various symbols/punctuation, e.g. inverted commas, dashes\n",
    "\n",
    "df.message = df.message.str.strip().str.replace(\"[‘’]\", \"\\'\")\n",
    "df.message = df.message.str.replace('[”“]','\"')\n",
    "df.message = df.message.str.replace('͟','')\n",
    "df.message = df.message.str.replace(\"–\",\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d3896a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove empty and null messages\n",
    "\n",
    "df.dropna(subset=['message'],inplace=True)\n",
    "df.drop(df[df.message.str.len() == 0].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c6990b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replace Chinese characters with the unk token\n",
    "\n",
    "df.message = df.message.str.replace('[㔹㘵㔳㜴㙆㘱㙅㘹㘸㜲㜳㜷㘶㙂㙃㐹㘴㜹㘷㜵㜶㔴䑅㘳㘲䐸㍄㜰]',tokenizer.unk_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004f16f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## uses frequency and tokenization to replace 'weird' and infrequent characters\n",
    "## gets the frequency for characters in O(N) time\n",
    "## tokenizes the text; identifies characters tokenized as more than one token (i.e. weird characters)\n",
    "\n",
    "freq = defaultdict(lambda:0)\n",
    "def addfreq(l):\n",
    "        for i in j:\n",
    "            freq[i] += 1\n",
    "\n",
    "#tqdm.pandas()\n",
    "df.message.apply(addfreq)\n",
    "\n",
    "freq2 = {i:j for i,j in freq.items() if j < 100000 and len(tokenizer.tokenize(i))>1}\n",
    "freq2 = pd.Series(freq2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e2df68",
   "metadata": {},
   "outputs": [],
   "source": [
    "## replaces any 'weird' character that appears <100 times with the 'unk' token\n",
    "df.message = df.message.str.replace(\"[\" + \"\".join(freq2[freq2<100].keys()) + \"]\", tokenizer.unk_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a491e329",
   "metadata": {},
   "outputs": [],
   "source": [
    "## visual check of the rest of the tokens\n",
    "freq2[freq2>=100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922d5542",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replaces emojis with an [emoji] token as well as the actual emoji in bytes \n",
    "## (which will hopefully help it recongize emojis that are too infrequent and were replaced with unk)\n",
    "\n",
    "def to_emoji(a):\n",
    "    if len(a) == 10:\n",
    "        return to_emoji(a[:5]) + to_emoji(a[5:])\n",
    "    return chr(int(\"0x\"+a,16))\n",
    "df.message = df.message.str.replace(\"\\[emoji(\\w+)\\]\",lambda a:\"[emoji]\"+ to_emoji(a.groups()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba58f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(save_directory+'messages_without_weird_characters.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc007c0",
   "metadata": {},
   "source": [
    "### Conversation lengths (Fixing outliers)\n",
    "\n",
    "<p> If bimodal distribution, use the plot to cut down on the lower end of messages. On the higher end, remove conversations with length > 2 x IQR + mean.\n",
    "<br><br> Consider whether it would make sense to count the number of word/characters per conversation; because you can have very long (but very few) messages. Keep in mind that long messages MAY correspond with long conversations (i.e. conversations with many messages). \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e5a1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(save_directory+'messages_without_weird_characters.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ced6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## gets the conversations lengths for each conversation\n",
    "conversation_lengths = df[df.interaction!='bot'].groupby('conversation_id').message.agg(lambda x : sum(len(i) for i in x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07a81d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plots the raw distribution for the number of messages per conversation\n",
    "\n",
    "conversation_lengths.hist(bins=200)\n",
    "plt.plot([1200, 1200], [0, 60000])\n",
    "plt.plot([2200, 2200], [0, 60000], color='red')\n",
    "# plt.xlim(right=25000)\n",
    "plt.grid()\n",
    "plt.xlabel(\"Number of messages per conversation (excl. non-bot characters)\")\n",
    "plt.ylabel(\"Number of conversations\")\n",
    "plt.title(\"Histogram of conversation.lengths\")\n",
    "plt.savefig(\"figs/conversation_length_histogram.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45725e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plots the raw distribution for the number of messages per conversation\n",
    "\n",
    "conversation_lengths.hist(bins=200)\n",
    "plt.plot([1200, 1200], [0, 80000])\n",
    "plt.plot([2200, 2200], [0, 80000], color='red')\n",
    "plt.grid()\n",
    "plt.xlabel(\"Number of messages per conversation (excl. non-bot characters)\")\n",
    "plt.ylabel(\"Number of conversations\")\n",
    "plt.title(\"Histogram of conversation.lengths\")\n",
    "plt.savefig(\"figs/conversation_length_histogram.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20114292",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cuts the number of conversations down using the criteria determined above. \n",
    "## plots the number of messages for the selected conversations. \n",
    "## remember to update the minimum length and maximum length you want. \n",
    "\n",
    "iqr = conversation_lengths.quantile(0.75) - conversation_lengths.quantile(0.25)\n",
    "min_len = 1200\n",
    "max_len = conversation_lengths.mean() + 2*iqr\n",
    "print(f\"removing from below {(conversation_lengths<min_len).mean() * 100:.2f}%\")\n",
    "print(f\"removing from above {(conversation_lengths>max_len).mean() * 100:.2f}%\")\n",
    "conversation_lengths.hist(bins=200)\n",
    "y = 31000\n",
    "plt.plot([min_len, min_len, max_len,max_len, min_len],[y,0,0,y,y])\n",
    "plt.grid()\n",
    "plt.xlim(right=25000)\n",
    "plt.xlabel(\"Conversation Length (non-bot characters) with minor preprocessing\")\n",
    "plt.ylabel(\"Number of Conversations\")\n",
    "plt.title(\"Histogram of conversation lengths\");\n",
    "plt.savefig(\"figs/conversation_length_histogram_selected.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e66cda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cuts down the number of messages kept using the criteria described above\n",
    "## saves the final dataset with the wanted messages\n",
    "\n",
    "convo_ids = conversation_lengths[((conversation_lengths>min_len) & (conversation_lengths<max_len))].index\n",
    "df2 = df[df.conversation_id.isin(convo_ids)]\n",
    "df2.to_pickle(save_directory+'selected_messages.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4c15c7",
   "metadata": {},
   "source": [
    "### Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3db1e067",
   "metadata": {},
   "outputs": [],
   "source": [
    "## loads the messages\n",
    "df = pd.read_pickle(save_directory+\"selected_messages.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a5c8700",
   "metadata": {},
   "outputs": [],
   "source": [
    "## shuffles the conversations by conversation id\n",
    "\n",
    "all_convo_ids = df.conversation_id.unique()\n",
    "np.random.default_rng(42).shuffle(all_convo_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8d8e9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## splits the conversations. 5% of the conversations are kept for testing. \n",
    "\n",
    "l = len(all_convo_ids);l\n",
    "test_size = int(l*0.05)\n",
    "test_convos = set(all_convo_ids[:test_size])\n",
    "train_convos = set(all_convo_ids[test_size:])\n",
    "\n",
    "torch.save(train_convos, save_directory+\"train_convos.torch\")\n",
    "torch.save(test_convos, save_directory+\"test_convos.torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58940429",
   "metadata": {},
   "source": [
    "### Pre-processing texter survey (TEXTER_SURVEY_RESPONSE.tsv/TEXTER_SURVEY_RESPONSE_VALUE.tsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6b1daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## getting texter messages \n",
    "\n",
    "messages = pd.read_pickle(save_directory+'messages_with_actors.pickle')\n",
    "texters = messages[messages.interaction == 'texter'].groupby('conversation_id').actor_id.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4165da",
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading and standardizing column names \n",
    "texter_survey_response = pd.read_csv(raw_directory+\"TEXTER_SURVEY_RESPONSE.tsv\", sep=\"\\t\")\n",
    "texter_survey_response_value = pd.read_csv(raw_directory+\"TEXTER_SURVEY_RESPONSE_VALUE.tsv\", sep=\"\\t\")\n",
    "texter_survey_response_value.columns = [i.lower() for i in texter_survey_response_value]\n",
    "texter_survey_response.columns = texter_survey_response.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c9374c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where the value is N/A\n",
    "texter_survey_response_value = texter_survey_response_value[~texter_survey_response_value.value.isna()]\n",
    "\n",
    "# Convert question numbers from float to str (via int)\n",
    "texter_survey_response_value.question_id = texter_survey_response_value.question_id.apply(lambda x: str(int(x)))\n",
    "\n",
    "# Find questions where a single survey has multiple answers, not counting the flag \"Other - Write In\"\n",
    "g = texter_survey_response_value[texter_survey_response_value.value!='Other - Write In'].groupby(['response_id','question_id'])\n",
    "a = g.count().value[g.count().value>1].index.to_frame().question_id.unique()\n",
    "a.sort()\n",
    "\n",
    "checkbox_questions = list(a)\n",
    "\n",
    "print(\"The following questions are being treated as 'checkbox questions':\")\n",
    "\", \".join(checkbox_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d8c6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## sets up the dataframe for collated texter responses with with columns: question_id and index: response_id \n",
    "\n",
    "texter_survey_collated = pd.DataFrame(\n",
    "    columns=texter_survey_response_value.question_id.unique(), \n",
    "    index = texter_survey_response_value.response_id.unique()\n",
    ")\n",
    "\n",
    "texter_survey_collated = texter_survey_collated.applymap(lambda x:[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29b8c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This generates the collated dataframe, (i.e. with the responses) Should take ~2-3 mins to run. Could be\n",
    "\n",
    "for _, _, response_id, question_id, value, _ in tqdm(texter_survey_response_value.itertuples(),\n",
    "                                                     total=texter_survey_response_value.shape[0]):\n",
    "#     response_id = int(response_id)\n",
    "    texter_survey_collated.loc[response_id, question_id].append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26da49fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## I think it's dropping out empty responses?  \n",
    "\n",
    "texter_survey_collated = texter_survey_collated.applymap(lambda a: a if len(a) > 0 else np.nan)\n",
    "cols = [texter_survey_collated[i].dropna().apply(len).max() for i in texter_survey_collated]\n",
    "cols = texter_survey_collated.columns[[i == 1 for i in cols]]\n",
    "texter_survey_collated[cols] = texter_survey_collated[cols].applymap(lambda a: a[0] if type(a)==list else a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6169805f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## joins the texter_survey_response (i.e. other information about texter_survey_response, e.g. time of submission, etc.)\n",
    "## with the collated texter survey on response_id\n",
    "\n",
    "texter_survey_response['response_id'] = texter_survey_response.id\n",
    "texter_survey_collated = texter_survey_response.drop([0]).join(texter_survey_collated, on=\"response_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b029979",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Not sure what's happening from this point\n",
    "\n",
    "a = [69, 71, 73, 74, 75, 151, 205, 72, 144, 145, 85, 86, 218, '221', '222', '223', '224', '227', '272', '273', '274', '275', '278', '269', 217, 70, 292, 270, '152', '225', 240, 220, 219, 289, 291, 268, 238, 241]\n",
    "texter_demo_questions = [str(i) for i in sorted([int(i) for i in a])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785e38bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "texter_survey_collated.index = range(len(texter_survey_collated))\n",
    "\n",
    "actor_2_index = texter_survey_collated['actor_id'].to_frame().reset_index().groupby('actor_id').groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939bb50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(xx):\n",
    "    xx = list(xx)\n",
    "    assert len(xx) != 0\n",
    "    if len(xx) == 1:\n",
    "        return xx[0]\n",
    "    if any(type(x) == list for x in xx):\n",
    "        xx = [i for i in xx if type(i) == list]\n",
    "        return list({i for j in xx for i in j if not pd.isna(i)}) #flatten list\n",
    "    xx = [i for i in xx if not pd.isna(i)]\n",
    "    if len(xx) == 0:\n",
    "        return np.nan\n",
    "    xx = list(set(xx))\n",
    "    if len(xx) == 1:\n",
    "        return xx[0]\n",
    "    else:\n",
    "        return None # CONFLICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98163325",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "a = texter_survey_collated[texter_demo_questions+['actor_id']]\n",
    "a = a.groupby('actor_id').progress_apply(lambda a:a.apply(merge))\n",
    "a.drop('actor_id',axis=1,inplace=True)\n",
    "a.dropna(how='all',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b704c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_add = []\n",
    "\n",
    "def f(i):\n",
    "    global to_add\n",
    "    actor_id = i[0]\n",
    "    convo_ids = list(texters[texters == actor_id].index)\n",
    "    vals = i[1].dropna()\n",
    "    index = actor_2_index[actor_id]\n",
    "    \n",
    "    for col,val in vals.iteritems():\n",
    "        if type(val) == list:\n",
    "            texter_survey_collated.loc[index.tolist(),col] = texter_survey_collated.loc[index.tolist(),col].apply(lambda _:val)\n",
    "        else:\n",
    "            texter_survey_collated.loc[index.tolist(),col] = val\n",
    "    \n",
    "    convo_ids = [i for i in convo_ids if i not in survey_convo_ids]\n",
    "    to_add += [{\"actor_id\":actor_id,\"conversation_id\":c, **vals} for c in convo_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b404818",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_convo_ids = set(texter_survey_collated.conversation_id)\n",
    "to_add = []\n",
    "for i in tqdm(a.iterrows(),total=a.shape[0]):\n",
    "    f(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f9589a",
   "metadata": {},
   "outputs": [],
   "source": [
    "texter_survey_collated2 = texter_survey_collated.append(to_add,ignore_index=True)\n",
    "texter_survey_collated2.to_pickle(save_directory+\"texter_survey_collated.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0ae336",
   "metadata": {},
   "source": [
    "### Pre-processing active rescues "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff028f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading file and standardizing column name \n",
    "## replaces all empty cells with NA \n",
    "\n",
    "reporting_log = pd.read_pickle(raw_directory+\"REPORTING_LOG.tsv\", sep=\"\\t\")\n",
    "reporting_log.columns=reporting_log.columns.str.lower()\n",
    "\n",
    "for col in reporting_log:\n",
    "    reporting_log[col] = reporting_log[col].replace(\"\",np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1f6d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## not entirely sure what's happening here \n",
    "\n",
    "report_type = reporting_log.groupby('conversation_id').type.agg(list)\n",
    "report_type.name = \"report_type\"\n",
    "report_sub_type = reporting_log.groupby('conversation_id').sub_type.agg(list)\n",
    "report_sub_type.name = \"report_sub_type\"\n",
    "any_finalized = reporting_log.groupby('conversation_id').finalized.max()\n",
    "any_finalized.name = \"any_finalized\"\n",
    "any_canceled = reporting_log.groupby('conversation_id').canceled.max()\n",
    "any_canceled.name = \"any_canceled\"\n",
    "all_canceled = reporting_log.groupby('conversation_id').canceled.min()\n",
    "all_canceled.name = \"all_canceled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db83616e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## drops all NA values \n",
    "## all empty report types or sub-types are replaced with NA value\n",
    "\n",
    "report_type=report_type.apply(lambda a: [i for i in a if not pd.isna(i)])\n",
    "report_sub_type=report_sub_type.apply(lambda a: [i for i in a if not pd.isna(i)])\n",
    "\n",
    "report_type.loc[report_type.apply(len) == 0] = np.nan\n",
    "report_sub_type.loc[report_sub_type.apply(len) == 0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd68c807",
   "metadata": {},
   "outputs": [],
   "source": [
    "## creates new dataframe with the report type, sub-type, finalized, cancelled, etc. \n",
    "\n",
    "report_by_convo_df = report_type.to_frame().join(report_sub_type,how='outer',)\\\n",
    "                                            .join(any_finalized,how='outer',)\\\n",
    "                                            .join(any_canceled,how='outer') \\\n",
    "                                            .join(all_canceled,how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f989859",
   "metadata": {},
   "source": [
    "### Pre-processing average counselor reviews "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec6f09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading the tsv\n",
    "## standardize column names\n",
    "\n",
    "conversation_participation = pd.read_csv(raw_directory+'CONVERSATION_PARTICIPATION.tsv', sep='\\t')\n",
    "conversation_participation.columns = [i.lower() for i in conversation_participation.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f1ff30",
   "metadata": {},
   "outputs": [],
   "source": [
    "## creates a column for the total time taken for the conversation\n",
    "## note that there may be multiple entries for each conversation (i.e. multiple entries for one conversation_id) hence next step\n",
    "conversation_participation[\"total_time\"] = pd.to_datetime(conversation_participation.ended_on) - pd.to_datetime(conversation_participation.created_on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578289c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## gets the total time for each conversation \n",
    "\n",
    "counselor_interactions = conversation_participation[conversation_participation.interaction == \"counselor\"]\n",
    "counselor_by_convo = {}\n",
    "for c_id, group in tqdm(counselor_interactions.groupby(\"conversation_id\")):\n",
    "    if group.shape[0] == 1:\n",
    "        m = group.actor_id.values[0]\n",
    "    else:\n",
    "        m = group.actor_id.values[group.total_time.argmax()]\n",
    "    counselor_by_convo[c_id] = m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bb41de",
   "metadata": {},
   "outputs": [],
   "source": [
    "## gets the counselors tagged to each conversation\n",
    "\n",
    "counselor_by_convo = pd.Series(counselor_by_convo,name=\"counselor_actor_id\")\n",
    "counselor_by_convo.index.name = \"conversation_id\"\n",
    "counselor_by_convo.to_pickle(save_directory+\"counselor_by_convo.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319efda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "counselor_by_convo = pd.read_pickle(save_directory+\"counselor_by_convo.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c2c94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## getting helpfulness ratings\n",
    "\n",
    "texter_survey_collated = pd.read_pickle(save_directory+\"texter_survey_collated.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d75520",
   "metadata": {},
   "outputs": [],
   "source": [
    "## processing the helpfulness ratings\n",
    "\n",
    "helpful1 = texter_survey_collated[['conversation_id','64']].set_index('conversation_id')\n",
    "helpful1['64'] = helpful1['64'].replace({ \n",
    "    \"No\":0.0, \n",
    "    \"Yes\":1.0 \n",
    "}).dropna().astype('int')\n",
    "\n",
    "how_helpful = texter_survey_collated[['conversation_id', '65']].set_index('conversation_id').dropna()\n",
    "how_helpful['65'] = how_helpful['65'].str.replace(\"5 (very helpful)\", \"5\", regex=False)\n",
    "how_helpful['65'] = how_helpful['65'].str.replace(\"1 (slightly helpful)\", \"1\", regex=False)\n",
    "how_helpful[['65>1 (slightly helpful)','65>2', '65>3', '65>4']]=0\n",
    "for i in tqdm(how_helpful.index):\n",
    "    x = int(how_helpful.loc[i, '65'])\n",
    "    if (x > 4): \n",
    "        how_helpful.loc[i, ['65>1 (slightly helpful)','65>2', '65>3', '65>4']] += 1\n",
    "    elif (x > 3): \n",
    "        how_helpful.loc[i, ['65>1 (slightly helpful)','65>2', '65>3']] += 1\n",
    "    elif (x > 2): \n",
    "        how_helpful.loc[i, ['65>1 (slightly helpful)','65>2']] += 1\n",
    "    elif (x > 1): \n",
    "        how_helpful.loc[i, '65>1 (slightly helpful)'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf285303",
   "metadata": {},
   "outputs": [],
   "source": [
    "## joining counselor and convo IDs with helpfulness ratings. \n",
    "\n",
    "helpful_by_counselor = counselor_by_convo.to_frame().merge(helpful1, right_index=True, left_index=True).dropna()\n",
    "helpful_by_counselor = helpful_by_counselor.merge(how_helpful.dropna().drop(columns='65'), right_index=True, left_index=True, how='left')\n",
    "\n",
    "helpful_by_counselor_all = helpful_by_counselor.join(counselor_by_convo,how='right',lsuffix='blah').drop('counselor_actor_idblah',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea976717",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = defaultdict(list)\n",
    "rating_moving_average = dict()\n",
    "counselor_scores = dict()\n",
    "counselor_num_convos = defaultdict(lambda:0)\n",
    "gamma = 0.9\n",
    "data = dict()\n",
    "convo_counselor_num_convos = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371fef51",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(helpful_by_counselor_all.itertuples(), total=helpful_by_counselor_all.shape[0]):\n",
    "    # note that 1:-1 here indicates the other ratings i.e. 65>1, 65>2, etc. \n",
    "    conversation, counselor, current_rating = i[0], i[-1], i[1:-1] \n",
    "    \n",
    "    # seems to be tracking the number of conversations a counselor has \n",
    "    counselor_num_convos[counselor] += 1\n",
    "    \n",
    "    # seems to be tracking the conversations the counselor of this conversation had \n",
    "    convo_counselor_num_convos[conversation] = counselor_num_convos[counselor]\n",
    "    \n",
    "    # if there was a rating for this conversation\n",
    "    if pd.notna(current_rating[0]):\n",
    "        \n",
    "        # not entirely sure how += works with 5 columns; creates five rows? Gets rearranged into 5 columns\n",
    "        ratings[counselor] += current_rating\n",
    "        counselor_ratings = np.array(ratings[counselor]).reshape(-1, 5)\n",
    "        \n",
    "        # if there are more than 5 different ratings (i.e. for different conversations)...\n",
    "        # keep the ratings; calculate the all time mean and the last five mean\n",
    "        # not entirely sure why gamma is set to 0.9\n",
    "        if counselor_ratings.shape[0] >= 5:\n",
    "            current_rating = np.array(current_rating)\n",
    "\n",
    "            ## keeps track of the all time mean\n",
    "            all_time_mean = counselor_ratings.mean(0)\n",
    "\n",
    "            ## keeps track of the last five ratings\n",
    "            last_five_mean = counselor_ratings[-10:].mean(0)\n",
    "\n",
    "            ## moving average rating \n",
    "            if counselor in rating_moving_average:\n",
    "                rating_moving_average[counselor] = (rating_moving_average[counselor] * gamma) + (current_rating * (1-gamma))\n",
    "            else:\n",
    "                rating_moving_average[counselor] = all_time_mean\n",
    "\n",
    "            ## stores all the different metrics (all time + last 5 mean + moving averate) in counselor_scores\n",
    "            counselor_scores[counselor] = np.concatenate([all_time_mean,last_five_mean, rating_moving_average[counselor]])\n",
    "\n",
    "    ## tags the counselor scores to the conversation\n",
    "    ## doesn't update earlier scores but that's okay because the counselor was less 'skilled' then\n",
    "    if counselor in counselor_scores:\n",
    "        data[conversation] = counselor_scores[counselor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b236032",
   "metadata": {},
   "outputs": [],
   "source": [
    "## setting columns names for average counselor ratings\n",
    "\n",
    "cols = ['64_Yes','65>1 (slightly helpful)', '65>2', '65>3', '65>4']\n",
    "cols = cols*3\n",
    "cols[:5] = [\"all_time_avg_\"+i for i in cols[:5]]\n",
    "cols[5:10] = [\"last5_avg_\"+i for i in cols[:5]]\n",
    "cols[10:] = [\"moving_avg_\"+i for i in cols[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fba66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## don't understand the need for the transpose, but otherwise... \n",
    "counselor_skill = pd.DataFrame(data,index=cols).T\n",
    "counselor_skill = counselor_skill.join(pd.Series(convo_counselor_num_convos,name='counselor_num_convos'),how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82286f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "## not entirely certain what quantile transformer does\n",
    "\n",
    "quantile_transformer = preprocessing.QuantileTransformer()\n",
    "\n",
    "a = quantile_transformer.fit_transform(counselor_skill.values)\n",
    "m_perc = pd.DataFrame(a,columns = counselor_skill.columns, index=counselor_skill.index)\n",
    "\n",
    "torch.save((quantile_transformer,counselor_skill.columns),\"saved/quantile_transformer_skill.torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca26aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## saves the final result. \n",
    "\n",
    "m_perc.index.name = 'conversation_id'\n",
    "m_perc.to_pickle(save_directory+\"/counselor_skill.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc693654",
   "metadata": {},
   "source": [
    "### Label Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587707ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## importing data frames\n",
    "\n",
    "counselor_survey_by_conversation = pd.read_pickle(save_directory+\"/counselor_survey_by_conversation.pickle\")\n",
    "texter_survey_collated = pd.read_pickle(save_directory+\"/texter_survey_collated.pickle\")\n",
    "avg_counselor_stats = pd.read_pickle(save_directory+\"/counselor_skill.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79744afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## running checks and dropping unnnecessary columns\n",
    "\n",
    "assert texter_survey_collated.conversation_id.notna().all()\n",
    "assert texter_survey_collated.conversation_id.nunique() == texter_survey_collated.shape[0]\n",
    "\n",
    "texter_survey_collated.set_index('conversation_id', inplace=True)\n",
    "texter_survey_collated.drop(['survey_id','id'],axis=1,inplace=True)\n",
    "texter_survey_collated.drop(['actor_id','response_id','returning_responder','status','time_submitted','time_imported'],axis=1,inplace=True)\n",
    "\n",
    "avg_counselor_stats.index.name = 'conversation_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92495975",
   "metadata": {},
   "outputs": [],
   "source": [
    "## joining the tables\n",
    "\n",
    "l_df = counselor_survey_by_conversation.join(\n",
    "    texter_survey_collated, \n",
    "    how=\"outer\", \n",
    ")\n",
    "l_df = l_df.join(\n",
    "    avg_counselor_stats,\n",
    "    how=\"outer\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893338c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import messages\n",
    "df2 = pd.read_pickle(save_directory+\"/selected_messages.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a2c24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## age regex\n",
    "texter_messages = df2[df2.interaction == \"texter\"].groupby('conversation_id').message.agg(\" \".join)\n",
    "search = '\\\\bI\\\\\\'?m (\\d+)(?! ?%)\\\\b'\n",
    "l = texter_messages[texter_messages.str.contains(search)].str.findall(search)\n",
    "l = l[l.apply(len) == 1].apply(lambda a:a[0]).astype('int')\n",
    "l = l[(l>=10) & (l<=70)]\n",
    "l.name = \"age_re\"\n",
    "l_df = l_df.join(l,how=\"outer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb7ec32",
   "metadata": {},
   "source": [
    "### Pre-processing Active Rescues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c698da",
   "metadata": {},
   "outputs": [],
   "source": [
    "reporting_log = pd.read_csv(raw_directory+\"/REPORTING_LOG.tsv\", sep=\"\\t\")\n",
    "reporting_log.columns=reporting_log.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eedfb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "reporting_log = pd.read_csv(raw_directory+\"/REPORTING_LOG.tsv\", sep=\"\\t\")\n",
    "reporting_log.columns=reporting_log.columns.str.lower()\n",
    "for col in reporting_log:\n",
    "    reporting_log[col] = reporting_log[col].replace(\"\",np.nan)\n",
    "    \n",
    "## gets report type\n",
    "report_type = reporting_log.groupby('conversation_id').type.agg(list)\n",
    "report_type.name = \"report_type\"\n",
    "\n",
    "## gets report sub-type\n",
    "report_sub_type = reporting_log.groupby('conversation_id').sub_type.agg(list)\n",
    "report_sub_type.name = \"report_sub_type\"\n",
    "\n",
    "## whether reports are finalized\n",
    "any_finalized = reporting_log.groupby('conversation_id').finalized.max()\n",
    "any_finalized.name = \"any_finalized\"\n",
    "\n",
    "## whether reports are cancelled\n",
    "any_canceled = reporting_log.groupby('conversation_id').canceled.max()\n",
    "any_canceled.name = \"any_canceled\"\n",
    "all_canceled = reporting_log.groupby('conversation_id').canceled.min()\n",
    "all_canceled.name = \"all_canceled\"\n",
    "\n",
    "\n",
    "report_type=report_type.apply(lambda a: [i for i in a if not pd.isna(i)])\n",
    "report_sub_type=report_sub_type.apply(lambda a: [i for i in a if not pd.isna(i)])\n",
    "\n",
    "report_type.loc[report_type.apply(len) == 0] = np.nan\n",
    "report_sub_type.loc[report_sub_type.apply(len) == 0] = np.nan\n",
    "\n",
    "report_by_convo_df = report_type.to_frame().join(report_sub_type,how='outer',)\\\n",
    "                                            .join(any_finalized,how='outer',)\\\n",
    "                                            .join(any_canceled,how='outer') \\\n",
    "                                            .join(all_canceled,how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ec47e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## joins l_df with the reporting log\n",
    "\n",
    "l_df = l_df.join(report_by_convo_df,how=\"outer\")\n",
    "l_df.loc[report_by_convo_df.index, \"report\"] = 1\n",
    "l_df['report'] = l_df['report'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6bd195",
   "metadata": {},
   "outputs": [],
   "source": [
    "## tentatively save l_df as pickle\n",
    "l_df.to_pickle(save_directory+\"/l_df.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3389b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "657c18ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_df = pd.read_pickle(save_directory+\"/l_df.pickle\")\n",
    "l = l_df.age_re[~l_df.age_re.isna()]\n",
    "avg_counselor_stats = pd.read_pickle(save_directory+\"/counselor_skill.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de4e418b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "convert_checkbox_to_binary:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "convert_ordinal_to_binary:   0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "convert_categorical_to_binary:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## attempt to imitate labelizer function\n",
    "labelizer = LabelProcessorSimplified(l_df,1000,200)\n",
    "labelizer.remove_prefer_not_to_answer()\n",
    "labelizer.convert_free_response('26',20)\n",
    "labelizer.convert_free_response('27',20)\n",
    "for i in [\"White\", \"English\", \"Asian\", \"British\", \"Mixed\", \"Black\"]:\n",
    "    labelizer.add_union(\"75\", i, substring=True)\n",
    "labelizer.convert_ordinal_to_binary(\"age_re\", sorted(l.unique()))\n",
    "\n",
    "labelizer.convert_mse(avg_counselor_stats.columns.tolist(), super_col=\"counselor_rank\")\n",
    "labelizer.convert_all_checkboxs_to_binary(200)\n",
    "labelizer.convert_all_ordinals_to_binary()\n",
    "labelizer.convert_remaining_to_categorical_binary(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "649e001b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## if the answer to 64 is not yes, all answers for 65 should be set to 0\n",
    "labelizer.df.loc[labelizer.df['64_Yes']==0,[\"65>1 (slightly helpful)\",\"65>2\",\"65>3\",\"65>4\"]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "faf00c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "## more labelizer functions\n",
    "labelizer.get_binary_softmax_indxs()\n",
    "labelizer.get_label_weights()\n",
    "labelizer.remove_analyzers()\n",
    "labelizer.drop_empty_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcc4a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "## casts the datatypes to floats. Not casting the IDs to uint because they're alphanumeric, not numeric (i.e. the unhashed ver.)\n",
    "for i,j in zip(labelizer.df.columns, labelizer.df.dtypes):\n",
    "    labelizer.df[i] = labelizer.df[i].astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b829baaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## recoding suicide risk because stages are spread out in multiple permutation columns instead of 4 binary columns \n",
    "suicide_risk = [i for i in l_df.columns if '19_[' in i]\n",
    "timeframe = []\n",
    "capability = []\n",
    "intent = []\n",
    "desire = []\n",
    "for i in suicide_risk: \n",
    "    if 'timeframe' in i:\n",
    "        timeframe.append(i)\n",
    "    elif 'capability' in i:\n",
    "        capability.append(i)\n",
    "    elif 'intent' in i:\n",
    "        intent.append(i)\n",
    "    elif 'desire' in i:\n",
    "        desire.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d6b1ecde",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_df[['19_desire_x', '19_intent_x', '19_capability_x', '19_timeframe_x']] = 0.0\n",
    "for i in tqdm(l_df.index):\n",
    "    for j in suicide_risk:\n",
    "        if l_df.loc[i, j] != 1.0:\n",
    "            continue\n",
    "        if 'desire' in j:\n",
    "            l_df.loc[i, '19_desire_x'] = 1.0\n",
    "        if 'intent' in j:\n",
    "            l_df.loc[i, '19_intent_x'] = 1.0\n",
    "        if 'capability' in j:\n",
    "            l_df.loc[i, '19_capability_x'] = 1.0\n",
    "        if 'timeframe' in j:\n",
    "            l_df.loc[i, '19_timeframe_x'] = 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "97170dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## recoding topics because of similar issue as suicide risk \n",
    "topics = [i for i in l_df.columns if '18_[' in i]\n",
    "substance = []\n",
    "depressed = []\n",
    "self_harm = []\n",
    "suicide = []\n",
    "for i in topics:\n",
    "    if 'substance' in i:\n",
    "        substance.append(i)\n",
    "    if 'depressed' in i:\n",
    "        depressed.append(i)\n",
    "    if 'self_harm' in i:\n",
    "        self_harm.append(i)\n",
    "    if 'suicide' in i:\n",
    "        suicide.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5ca7156f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9d9b0ab97344d9184d61ce828bb8352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/526256 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l_df[['18_substance', '18_depressed', '18_self_harm', '18_suicide']] = 0.0\n",
    "for i in tqdm(l_df.index):\n",
    "    for j in topics:\n",
    "        if l_df.loc[i, j] != 1.0:\n",
    "            continue\n",
    "        if 'substance' in j:\n",
    "            l_df.loc[i, '18_substance'] = 1.0\n",
    "        if 'depressed' in j:\n",
    "            l_df.loc[i, '18_depressed'] = 1.0\n",
    "        if 'self_harm' in j:\n",
    "            l_df.loc[i, '18_self_harm'] = 1.0\n",
    "        if 'suicide' in j:\n",
    "            l_df.loc[i, '18_suicide'] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2b993da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7481eb861f5c487d9f91e64af67ecc58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/526256 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "anxiety = [i for i in l_df.columns if 'anxiety' in i]\n",
    "l_df['18_anxiety'] = 0.0\n",
    "for i in tqdm(l_df.index):\n",
    "    l_df.loc[i, '18_anxiety'] = max(l_df.loc[i, anxiety])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad45dc97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    409712\n",
       "1.0     94979\n",
       "Name: 18_anxiety, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_df['18_anxiety'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "bc863c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## combining two columns for 24 or younger metric \n",
    "\n",
    "l_df.loc[:,'69>24 or younger'] = np.nan\n",
    "l_df.loc[(l_df.loc[:,'69>25-44']==0.0), '69>24 or younger'] = 1.0  \n",
    "l_df.loc[(l_df.loc[:,'69>25-44']==1.0), '69>24 or younger'] = 0.0 \n",
    "l_df.loc[(l_df.loc[:,'69>13 or younger']==0.0), '69>24 or younger'] = 0.0 \n",
    "l_df.loc[(l_df.loc[:,'69>25-44']==np.nan), '69>24 or younger'] = np.nan  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b9a40b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelizer.df = l_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6ee4561",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(labelizer,save_directory+'/labelizer.torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c7d7c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_directory+'/labelizer.pickle', 'wb') as f:\n",
    "    pickle.dump(labelizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58cbad66",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelizer = torch.load(save_directory+\"/labelizer.torch\")\n",
    "l_df = labelizer.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "21af9405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    523237\n",
      "1.0      3019\n",
      "Name: 18_substance, dtype: int64 \n",
      "\n",
      "0.0    503393\n",
      "1.0      1298\n",
      "Name: 18_[substance], dtype: int64 \n",
      "\n",
      "0.0    430115\n",
      "1.0     96141\n",
      "Name: 18_depressed, dtype: int64 \n",
      "\n",
      "0.0    485759\n",
      "1.0     18932\n",
      "Name: 18_[depressed], dtype: int64 \n",
      "\n",
      "0.0    421764\n",
      "1.0    104492\n",
      "Name: 18_suicide, dtype: int64 \n",
      "\n",
      "0.0    465631\n",
      "1.0     39060\n",
      "Name: 18_[suicide], dtype: int64 \n",
      "\n",
      "0.0    490239\n",
      "1.0     36017\n",
      "Name: 18_self_harm, dtype: int64 \n",
      "\n",
      "0.0    494262\n",
      "1.0     10429\n",
      "Name: 18_[self_harm], dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(l_df['18_substance'].value_counts(), \"\\n\")\n",
    "print(l_df['18_[substance]'].value_counts(), \"\\n\")\n",
    "print(l_df['18_depressed'].value_counts(), \"\\n\")\n",
    "print(l_df['18_[depressed]'].value_counts(), \"\\n\")\n",
    "print(l_df['18_suicide'].value_counts(), \"\\n\")\n",
    "print(l_df['18_[suicide]'].value_counts(), \"\\n\")\n",
    "print(l_df['18_self_harm'].value_counts(), \"\\n\")\n",
    "print(l_df['18_[self_harm]'].value_counts(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "cc8136df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    160091\n",
       "1.0     10511\n",
       "Name: 69>25-44, dtype: int64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_df['69>25-44'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "643c103c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    156995\n",
       "0.0     13607\n",
       "Name: 69>13 or younger, dtype: int64"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_df['69>13 or younger'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

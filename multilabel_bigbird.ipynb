{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9994c282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import pickle\n",
    "import transformers\n",
    "import torch\n",
    "import wandb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, confusion_matrix, \\\n",
    "                            multilabel_confusion_matrix, matthews_corrcoef, average_precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from transformers import AutoTokenizer, BigBirdForSequenceClassification, Trainer, TrainingArguments, \\\n",
    "                            RobertaForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a51ba31",
   "metadata": {},
   "source": [
    "## Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fe56d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelizer = torch.load(\"saved/labelizer.torch\")\n",
    "l_df = labelizer.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa790cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "wanted_labels = ['19_desire_x', '19_intent_x', '19_capability_x', '19_timeframe_x', \n",
    "                 '18_substance', '18_depressed', '18_self_harm', '18_anxiety', \n",
    "                 '64_Yes']\n",
    "df = l_df[wanted_labels].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c767423b",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = pd.read_pickle(\"saved/selected_messages.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "725e6530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n"
     ]
    }
   ],
   "source": [
    "%cd /\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d706c8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n"
     ]
    }
   ],
   "source": [
    "%cd /\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/bigbird-roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4050ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = texts.set_index('conversation_id')\n",
    "texts = texts.loc[texts.interaction=='texter', ['interaction', 'message']]\n",
    "texts['message'] = texts.message.str.strip().apply(lambda a:\" \"+a)\n",
    "texts['encoded_message'] = \" [\" + texts.interaction + \"] \" + texts.message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80dc0f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_conversations = texts.groupby(texts.index).encoded_message.agg(\" \".join).apply(\n",
    "    lambda a : f\"{tokenizer.bos_token}{a}{tokenizer.eos_token}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0c4c7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## adding labels to the text \n",
    "train_data = pd.DataFrame(encoded_conversations, index=encoded_conversations.index)\n",
    "train_data.columns=['text']\n",
    "train_data = pd.concat([train_data, df], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39d92e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(train_data, open(\"saved/texter_texts_with_multilabels.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0e6d0f",
   "metadata": {},
   "source": [
    "## Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aed58bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pickle.load(open(\"saved/texts_with_multilabels.pickle\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b02f5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## truncating longer sequences \n",
    "max_token_length = 512\n",
    "train_data['text'] = train_data.text.apply(lambda x: x if len(x.split()) < max_token_length else \" \".join(x.split()[:max_token_length]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "268ab5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n"
     ]
    }
   ],
   "source": [
    "%cd /\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "561ade26",
   "metadata": {},
   "outputs": [],
   "source": [
    "## padding to minimum length\n",
    "min_token_length = 704\n",
    "train_data['text'] = train_data.text.apply(lambda x: x if len(x.split()) >= min_token_length \n",
    "                                           else x + ((\" \" + tokenizer.pad_token)*(min_token_length - len(x.split()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67feceaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## sorting the dataset by length\n",
    "train_data['length'] = train_data.text.apply(lambda x: len(x.split()))\n",
    "train_data = train_data.sort_values('length', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3c7b1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame(train_data.set_index(\"text\"))\n",
    "train_data = train_data.astype('int32')\n",
    "train_data['labels'] = train_data[train_data.columns[:-1]].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a1b00d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## split into train and test data \n",
    "train_data, test_data = train_test_split(train_data, test_size=0.1)\n",
    "\n",
    "train_data = datasets.Dataset.from_pandas(train_data)\n",
    "test_data = datasets.Dataset.from_pandas(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df807475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ab0d8b045924a899a539870837d6db3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad6bfe8ccec84394958b2fba67869d82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cols = train_data.column_names\n",
    "cols.remove('labels')\n",
    "\n",
    "## tokenizing the text\n",
    "def tokenization(batched_text):\n",
    "    return tokenizer(batched_text['text'], padding = True, truncation=True, max_length = 512)\n",
    "\n",
    "train_data = train_data.map(tokenization, batched = True, batch_size = len(train_data), remove_columns=cols)\n",
    "test_data = test_data.map(tokenization, batched = True, batch_size = len(test_data), remove_columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9964408",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "test_data.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "615315e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data-imperial\n"
     ]
    }
   ],
   "source": [
    "%cd /data-imperial\n",
    "pickle.dump(train_data, open(\"saved/roberta/ml_train_ds.pickle\", \"wb\"))\n",
    "pickle.dump(test_data, open(\"saved/roberta/ml_test_ds.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91d4fd4",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c2df074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data-imperial\n"
     ]
    }
   ],
   "source": [
    "%cd /data-imperial/\n",
    "\n",
    "train_data = pickle.load(open('saved/ml_train_ds.pickle', 'rb'))\n",
    "test_data = pickle.load(open('saved/ml_test_ds.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b184df26",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = 'bigbird/output/finetune-ml/epoch-4'\n",
    "model = BigBirdForSequenceClassification.from_pretrained(checkpoint, \n",
    "                                                        num_labels=9)\n",
    "\n",
    "# model.save_pretrained(\"data-imperial/bigbird\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fde8a69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bigbird\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f106a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics for training evaluation\n",
    "# def compute_metrics(pred):\n",
    "#     labels = pred.label_ids\n",
    "#     pred_proba = torch.from_numpy(pred.predictions).sigmoid()\n",
    "#     preds = (pred_proba>0.5).detach().numpy().astype('int32')\n",
    "#     precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "#     acc = accuracy_score(labels, preds)\n",
    "#     auprc = average_precision_score(labels, preds, average='weighted')\n",
    "#     cm = multilabel_confusion_matrix(labels, preds)\n",
    "#     print([b for i in cm for b in i[0]])\n",
    "#     print([b for i in cm for b in i[1]])\n",
    "#     return {\n",
    "#         'accuracy': acc,\n",
    "#         'f1': f1,\n",
    "#         'precision': precision,\n",
    "#         'recall': recall,\n",
    "#         'auprc': auprc\n",
    "#     }\n",
    "\n",
    "# metrics for final evaluation\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    pred_proba = torch.from_numpy(pred.predictions).sigmoid()\n",
    "    preds = (pred_proba>0.5).detach().numpy().astype('int32')\n",
    "    df = []\n",
    "    for i in range(9):\n",
    "        label = labels[:,i]\n",
    "        pred = preds[:,i]\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(label, pred, average='binary')\n",
    "        acc = accuracy_score(label, pred)\n",
    "        auprc = average_precision_score(label, pred)\n",
    "        mcc = matthews_corrcoef(label, pred)\n",
    "        df.append([precision, recall, f1, acc, auprc, mcc])\n",
    "        print(confusion_matrix(label, pred, labels=[0,1]))\n",
    "    df = pd.DataFrame(df, columns=['precision', 'recall', 'f1', 'acc', 'auprc', 'mcc'])\n",
    "    print(df)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'auprc': auprc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a301e50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = 'bigbird/output/finetune-ml',\n",
    "    num_train_epochs = 5,\n",
    "    per_device_train_batch_size = 2,\n",
    "    gradient_accumulation_steps = 32,    \n",
    "    per_device_eval_batch_size= 2,\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    disable_tqdm = False, \n",
    "    load_best_model_at_end=False,\n",
    "    warmup_steps=160,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps = 4,\n",
    "    learning_rate = 1e-5,\n",
    "    log_level = 'warning', \n",
    "    fp16 = True,\n",
    "    logging_dir='bigbird/logs/finetune-ml',\n",
    "    dataloader_num_workers = 0,\n",
    "    run_name = 'bigbird_ml_classification_test'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1c22b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "## custom trainer class for multilabel training\n",
    "class MultilabelTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        loss_fct = BCEWithLogitsLoss()\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels),\n",
    "                        labels.float().view(-1, self.model.config.num_labels))\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2864c458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data-imperial\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd /data-imperial\n",
    "\n",
    "# instantiate the trainer class and check for available devices\n",
    "trainer = MultilabelTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=test_data\n",
    ")\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3758ec9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkiatann\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.0 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.11.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">bigbird_ml_classification_test</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/kiatann/huggingface\" target=\"_blank\">https://wandb.ai/kiatann/huggingface</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/kiatann/huggingface/runs/16ixajce\" target=\"_blank\">https://wandb.ai/kiatann/huggingface/runs/16ixajce</a><br/>\n",
       "                Run data is saved locally in <code>/data-imperial/wandb/run-20210824_075246-16ixajce</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data-imperial/lib/python3.9/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448238472/work/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='941' max='3855' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 941/3855 6:17:41 < 19:32:05, 0.04 it/s, Epoch 1.22/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auprc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.172400</td>\n",
       "      <td>0.204964</td>\n",
       "      <td>0.447220</td>\n",
       "      <td>0.798429</td>\n",
       "      <td>0.790415</td>\n",
       "      <td>0.807258</td>\n",
       "      <td>0.715852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data-imperial/lib/python3.9/site-packages/transformers/trainer.py:1314: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  nn.utils.clip_grad_norm_(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3783, 294, 4624, 164, 4903, 146, 5261, 67, 5460, 4, 3564, 590, 4809, 168, 3426, 580, 395, 325]\n",
      "[306, 1102, 120, 577, 83, 353, 73, 84, 16, 5, 542, 789, 147, 361, 509, 970, 286, 4479]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18921/225503531.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/data-imperial/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1284\u001b[0m                         \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1286\u001b[0;31m                     \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1287\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_flos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating_point_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data-imperial/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1766\u001b[0m         \"\"\"\n\u001b[1;32m   1767\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1768\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1770\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_sagemaker_mp_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data-imperial/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_prepare_inputs\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1740\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhf_deepspeed_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1742\u001b[0;31m                 \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1744\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpast_index\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_past\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4a0388",
   "metadata": {},
   "source": [
    "## Experiment on Texters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eeb2d26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data-imperial/lib/python3.9/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448238472/work/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53022' max='27421' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27421/27421 3:48:32]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[39958   590]\n",
      " [10182  4112]]\n",
      "[[47784    73]\n",
      " [ 6165   820]]\n",
      "[[50275    22]\n",
      " [ 4272   273]]\n",
      "[[53246     2]\n",
      " [ 1563    31]]\n",
      "[[54489   112]\n",
      " [  171    70]]\n",
      "[[37872  3869]\n",
      " [ 7277  5824]]\n",
      "[[47830  2273]\n",
      " [ 1508  3231]]\n",
      "[[34198  5935]\n",
      " [ 5249  9460]]\n",
      "[[ 5886  1088]\n",
      " [10733 37135]]\n",
      "   precision    recall        f1       acc     auprc       mcc\n",
      "0   0.874521  0.287673  0.432933  0.803581  0.437237  0.428238\n",
      "1   0.918253  0.117394  0.208175  0.886255  0.220212  0.305215\n",
      "2   0.925424  0.060066  0.112810  0.921702  0.133483  0.224748\n",
      "3   0.939394  0.019448  0.038107  0.971463  0.046769  0.132968\n",
      "4   0.384615  0.290456  0.330969  0.994840  0.114832  0.331697\n",
      "5   0.600846  0.444546  0.511012  0.796762  0.399794  0.393319\n",
      "6   0.587028  0.681789  0.630870  0.931056  0.427726  0.595101\n",
      "7   0.614485  0.643144  0.628488  0.796069  0.490914  0.488291\n",
      "8   0.971535  0.775779  0.862692  0.784454  0.949405  0.449294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkiatann\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.0 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.11.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">bigbird_ml_classification_test</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/kiatann/huggingface\" target=\"_blank\">https://wandb.ai/kiatann/huggingface</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/kiatann/huggingface/runs/23qokl24\" target=\"_blank\">https://wandb.ai/kiatann/huggingface/runs/23qokl24</a><br/>\n",
       "                Run data is saved locally in <code>/data-imperial/wandb/run-20210813_055553-23qokl24</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.32863667607307434,\n",
       " 'eval_accuracy': 0.7844535210240327,\n",
       " 'eval_f1': 0.8626918028597647,\n",
       " 'eval_precision': 0.9715354629411611,\n",
       " 'eval_recall': 0.7757792262053982,\n",
       " 'eval_auprc': 0.9494046989761449,\n",
       " 'eval_runtime': 7168.104,\n",
       " 'eval_samples_per_second': 7.651,\n",
       " 'eval_steps_per_second': 3.825}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(eval_dataset=train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56fc2aa",
   "metadata": {},
   "source": [
    "## Experiment for Helpfulness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f75dd530",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data-imperial/lib/python3.9/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448238472/work/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27421' max='27421' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27421/27421 1:57:50]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[37969  2579]\n",
      " [ 3554 10740]]\n",
      "[[46758  1099]\n",
      " [ 1710  5275]]\n",
      "[[49449   848]\n",
      " [ 1485  3060]]\n",
      "[[52984   264]\n",
      " [ 1188   406]]\n",
      "[[54475   126]\n",
      " [  154    87]]\n",
      "[[34348  7393]\n",
      " [ 5109  7992]]\n",
      "[[48360  1743]\n",
      " [ 1652  3087]]\n",
      "[[34372  5761]\n",
      " [ 5082  9627]]\n",
      "[[ 2738  4236]\n",
      " [ 3360 44508]]\n",
      "   precision    recall        f1       acc     auprc       mcc\n",
      "0   0.806367  0.751364  0.777894  0.888170  0.670680  0.704075\n",
      "1   0.827581  0.755190  0.789730  0.948780  0.656161  0.761671\n",
      "2   0.783009  0.673267  0.724003  0.957460  0.554252  0.703445\n",
      "3   0.605970  0.254705  0.358657  0.973524  0.176006  0.381919\n",
      "4   0.408451  0.360996  0.383260  0.994894  0.150257  0.381438\n",
      "5   0.519467  0.610030  0.561118  0.772036  0.410049  0.410889\n",
      "6   0.639130  0.651403  0.645208  0.938095  0.446455  0.611334\n",
      "7   0.625617  0.654497  0.639732  0.802287  0.502131  0.503830\n",
      "8   0.913097  0.929807  0.921376  0.861493  0.910271  0.341677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkiatann\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.0 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.11.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">bigbird_ml_classification_test</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/kiatann/huggingface\" target=\"_blank\">https://wandb.ai/kiatann/huggingface</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/kiatann/huggingface/runs/2s4lr926\" target=\"_blank\">https://wandb.ai/kiatann/huggingface/runs/2s4lr926</a><br/>\n",
       "                Run data is saved locally in <code>/data-imperial/wandb/run-20210813_094322-2s4lr926</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.23033231496810913,\n",
       " 'eval_accuracy': 0.8614930163013749,\n",
       " 'eval_f1': 0.9213762265557074,\n",
       " 'eval_precision': 0.9130969965534219,\n",
       " 'eval_recall': 0.9298069691652043,\n",
       " 'eval_auprc': 0.9102708631397491,\n",
       " 'eval_runtime': 7071.7171,\n",
       " 'eval_samples_per_second': 7.755,\n",
       " 'eval_steps_per_second': 3.878}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(eval_dataset=train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262ea600",
   "metadata": {},
   "source": [
    "## Evaluation for Epoch 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa1746a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data-imperial/lib/python3.9/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448238472/work/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2743' max='2743' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2743/2743 13:32]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3711  366]\n",
      " [ 261 1147]]\n",
      "[[4618  170]\n",
      " [ 109  588]]\n",
      "[[4889  160]\n",
      " [  85  351]]\n",
      "[[5274   54]\n",
      " [  98   59]]\n",
      "[[5464    0]\n",
      " [  21    0]]\n",
      "[[3784  370]\n",
      " [ 677  654]]\n",
      "[[4831  146]\n",
      " [ 159  349]]\n",
      "[[3724  282]\n",
      " [ 729  750]]\n",
      "[[ 274  446]\n",
      " [ 149 4616]]\n",
      "   precision    recall        f1       acc     auprc       mcc\n",
      "0   0.758096  0.814631  0.785347  0.885688  0.665153  0.708437\n",
      "1   0.775726  0.843615  0.808247  0.949134  0.674287  0.779896\n",
      "2   0.686888  0.805046  0.741288  0.955333  0.568474  0.719718\n",
      "3   0.522124  0.375796  0.437037  0.972288  0.214079  0.429243\n",
      "4   0.000000  0.000000  0.000000  0.996171  0.003829  0.000000\n",
      "5   0.638672  0.491360  0.555414  0.809116  0.437245  0.442583\n",
      "6   0.705051  0.687008  0.695912  0.944394  0.513363  0.665385\n",
      "7   0.726744  0.507099  0.597372  0.815679  0.501439  0.495863\n",
      "8   0.911893  0.968730  0.939453  0.891522  0.910543  0.442127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data-imperial/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data-imperial/lib/python3.9/site-packages/sklearn/metrics/_classification.py:873: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkiatann\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.11.2 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.11.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">bigbird_ml_classification_test</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/kiatann/huggingface\" target=\"_blank\">https://wandb.ai/kiatann/huggingface</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/kiatann/huggingface/runs/3l06yvp7\" target=\"_blank\">https://wandb.ai/kiatann/huggingface/runs/3l06yvp7</a><br/>\n",
       "                Run data is saved locally in <code>/data-imperial/wandb/run-20210808_051401-3l06yvp7</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.20128501951694489,\n",
       " 'eval_accuracy': 0.8915223336371924,\n",
       " 'eval_f1': 0.9394525287473288,\n",
       " 'eval_precision': 0.9118925325958119,\n",
       " 'eval_recall': 0.9687303252885624,\n",
       " 'eval_auprc': 0.9105429451718668,\n",
       " 'eval_runtime': 813.6131,\n",
       " 'eval_samples_per_second': 6.742,\n",
       " 'eval_steps_per_second': 3.371}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237ab1e6",
   "metadata": {},
   "source": [
    "## Epoch 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "774d6811",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data-imperial/lib/python3.9/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448238472/work/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2743' max='2743' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2743/2743 13:35]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3637  440]\n",
      " [ 199 1209]]\n",
      "[[4571  217]\n",
      " [  75  622]]\n",
      "[[4823  226]\n",
      " [  47  389]]\n",
      "[[5248   80]\n",
      " [  79   78]]\n",
      "[[5464    0]\n",
      " [  21    0]]\n",
      "[[3749  405]\n",
      " [ 655  676]]\n",
      "[[4867  110]\n",
      " [ 201  307]]\n",
      "[[3796  210]\n",
      " [ 778  701]]\n",
      "[[ 245  475]\n",
      " [ 118 4647]]\n",
      "   precision    recall        f1       acc     auprc       mcc\n",
      "0   0.733172  0.858665  0.790972  0.883500  0.665829  0.715176\n",
      "1   0.741359  0.892396  0.809896  0.946764  0.675259  0.783780\n",
      "2   0.632520  0.892202  0.740247  0.950228  0.572905  0.726529\n",
      "3   0.493671  0.496815  0.495238  0.971012  0.259666  0.480318\n",
      "4   0.000000  0.000000  0.000000  0.996171  0.003829  0.000000\n",
      "5   0.625347  0.507889  0.560531  0.806746  0.437023  0.442268\n",
      "6   0.736211  0.604331  0.663784  0.943300  0.481560  0.636830\n",
      "7   0.769484  0.473969  0.586611  0.819872  0.506553  0.502665\n",
      "8   0.907263  0.975236  0.940022  0.891887  0.906309  0.428591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data-imperial/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data-imperial/lib/python3.9/site-packages/sklearn/metrics/_classification.py:873: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkiatann\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.11.2 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.11.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">bigbird_ml_classification_test</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/kiatann/huggingface\" target=\"_blank\">https://wandb.ai/kiatann/huggingface</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/kiatann/huggingface/runs/1c8amblp\" target=\"_blank\">https://wandb.ai/kiatann/huggingface/runs/1c8amblp</a><br/>\n",
       "                Run data is saved locally in <code>/data-imperial/wandb/run-20210808_083525-1c8amblp</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.20445317029953003,\n",
       " 'eval_accuracy': 0.8918869644484959,\n",
       " 'eval_f1': 0.9400222514412865,\n",
       " 'eval_precision': 0.9072627879734478,\n",
       " 'eval_recall': 0.9752360965372507,\n",
       " 'eval_auprc': 0.9063086377436383,\n",
       " 'eval_runtime': 815.736,\n",
       " 'eval_samples_per_second': 6.724,\n",
       " 'eval_steps_per_second': 3.363}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9abb900",
   "metadata": {},
   "source": [
    "## Epoch 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20d02092",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data-imperial/lib/python3.9/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448238472/work/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2743' max='2743' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2743/2743 13:30]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3765  312]\n",
      " [ 319 1089]]\n",
      "[[4652  136]\n",
      " [ 150  547]]\n",
      "[[4931  118]\n",
      " [ 108  328]]\n",
      "[[5289   39]\n",
      " [ 101   56]]\n",
      "[[5454   10]\n",
      " [  16    5]]\n",
      "[[3493  661]\n",
      " [ 499  832]]\n",
      "[[4830  147]\n",
      " [ 165  343]]\n",
      "[[3484  522]\n",
      " [ 545  934]]\n",
      "[[ 380  340]\n",
      " [ 329 4436]]\n",
      "   precision    recall        f1       acc     auprc       mcc\n",
      "0   0.777302  0.773438  0.775365  0.884959  0.659353  0.698051\n",
      "1   0.800878  0.784792  0.792754  0.947858  0.655870  0.762986\n",
      "2   0.735426  0.752294  0.743764  0.958797  0.572946  0.721419\n",
      "3   0.589474  0.356688  0.444444  0.974476  0.228672  0.446539\n",
      "4   0.333333  0.238095  0.277778  0.995260  0.082282  0.279399\n",
      "5   0.557267  0.625094  0.589235  0.788514  0.439320  0.448802\n",
      "6   0.700000  0.675197  0.687375  0.943118  0.502720  0.656228\n",
      "7   0.641484  0.631508  0.636457  0.805469  0.504464  0.503702\n",
      "8   0.928811  0.930955  0.929882  0.878031  0.924663  0.461745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkiatann\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.11.2 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.11.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">bigbird_ml_classification_test</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/kiatann/huggingface\" target=\"_blank\">https://wandb.ai/kiatann/huggingface</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/kiatann/huggingface/runs/2vr3xq1w\" target=\"_blank\">https://wandb.ai/kiatann/huggingface/runs/2vr3xq1w</a><br/>\n",
       "                Run data is saved locally in <code>/data-imperial/wandb/run-20210808_090126-2vr3xq1w</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.2092665731906891,\n",
       " 'eval_accuracy': 0.8780309936189608,\n",
       " 'eval_f1': 0.9298815637773818,\n",
       " 'eval_precision': 0.9288107202680067,\n",
       " 'eval_recall': 0.9309548793284366,\n",
       " 'eval_auprc': 0.9246626404654953,\n",
       " 'eval_runtime': 810.754,\n",
       " 'eval_samples_per_second': 6.765,\n",
       " 'eval_steps_per_second': 3.383}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3c5a7e",
   "metadata": {},
   "source": [
    "## MultiLabel RoBERTa Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91f4c0a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2743' max='2743' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2743/2743 03:14]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3729  328]\n",
      " [ 401 1027]]\n",
      "[[4661  151]\n",
      " [ 195  478]]\n",
      "[[4894  152]\n",
      " [ 137  302]]\n",
      "[[5259   62]\n",
      " [  98   66]]\n",
      "[[5462    1]\n",
      " [  20    2]]\n",
      "[[3872  288]\n",
      " [ 797  528]]\n",
      "[[4878  133]\n",
      " [ 235  239]]\n",
      "[[3745  332]\n",
      " [ 702  706]]\n",
      "[[  45  673]\n",
      " [  35 4732]]\n",
      "   precision    recall        f1       acc     auprc       mcc\n",
      "0   0.757934  0.719188  0.738052  0.867092  0.618205  0.649492\n",
      "1   0.759936  0.710253  0.734255  0.936919  0.575298  0.699027\n",
      "2   0.665198  0.687927  0.676372  0.947311  0.482585  0.647810\n",
      "3   0.515625  0.402439  0.452055  0.970830  0.225375  0.440852\n",
      "4   0.666667  0.090909  0.160000  0.996171  0.064252  0.245261\n",
      "5   0.647059  0.398491  0.493227  0.802188  0.403152  0.396037\n",
      "6   0.642473  0.504219  0.565012  0.932908  0.366792  0.533798\n",
      "7   0.680154  0.501420  0.577269  0.811486  0.469029  0.468356\n",
      "8   0.875486  0.992658  0.930397  0.870921  0.875439  0.155675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkiatann\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.0 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.11.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">roberta_ml_classification_test</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/kiatann/huggingface\" target=\"_blank\">https://wandb.ai/kiatann/huggingface</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/kiatann/huggingface/runs/2w8p4ggj\" target=\"_blank\">https://wandb.ai/kiatann/huggingface/runs/2w8p4ggj</a><br/>\n",
       "                Run data is saved locally in <code>/data-imperial/wandb/run-20210815_060121-2w8p4ggj</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.23441153764724731,\n",
       " 'eval_accuracy': 0.8709206927985415,\n",
       " 'eval_f1': 0.9303971686983877,\n",
       " 'eval_precision': 0.8754856614246068,\n",
       " 'eval_recall': 0.9926578560939795,\n",
       " 'eval_auprc': 0.875438758908582,\n",
       " 'eval_runtime': 194.799,\n",
       " 'eval_samples_per_second': 28.157,\n",
       " 'eval_steps_per_second': 14.081}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a43621",
   "metadata": {},
   "source": [
    "## Finetuned Epoch 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dc9d2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data-imperial/lib/python3.9/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448238472/work/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2743' max='2743' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2743/2743 13:39]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data-imperial/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3661, 416, 4617, 171, 4897, 152, 5285, 43, 5464, 0, 3716, 438, 4808, 169, 3726, 280, 242, 478]\n",
      "[204, 1204, 91, 606, 75, 361, 93, 64, 21, 0, 640, 691, 154, 354, 714, 765, 102, 4663]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkiatann\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.0 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.11.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">bigbird_ml_classification_test</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/kiatann/huggingface\" target=\"_blank\">https://wandb.ai/kiatann/huggingface</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/kiatann/huggingface/runs/16vskrlt\" target=\"_blank\">https://wandb.ai/kiatann/huggingface/runs/16vskrlt</a><br/>\n",
       "                Run data is saved locally in <code>/data-imperial/wandb/run-20210824_074718-16vskrlt</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.20020583271980286,\n",
       " 'eval_accuracy': 0.4641750227894257,\n",
       " 'eval_f1': 0.7942772972955352,\n",
       " 'eval_precision': 0.7918829878640782,\n",
       " 'eval_recall': 0.8061470098129976,\n",
       " 'eval_auprc': 0.706824153451631,\n",
       " 'eval_runtime': 820.5507,\n",
       " 'eval_samples_per_second': 6.685,\n",
       " 'eval_steps_per_second': 3.343}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5060bdfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data-imperial/lib/python3.9/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448238472/work/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2743' max='2743' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2743/2743 13:40]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3661  416]\n",
      " [ 204 1204]]\n",
      "[[4617  171]\n",
      " [  91  606]]\n",
      "[[4897  152]\n",
      " [  75  361]]\n",
      "[[5285   43]\n",
      " [  93   64]]\n",
      "[[5464    0]\n",
      " [  21    0]]\n",
      "[[3716  438]\n",
      " [ 640  691]]\n",
      "[[4808  169]\n",
      " [ 154  354]]\n",
      "[[3726  280]\n",
      " [ 714  765]]\n",
      "[[ 242  478]\n",
      " [ 102 4663]]\n",
      "   precision    recall        f1       acc     auprc       mcc\n",
      "0   0.743210  0.855114  0.795244  0.886964  0.672721  0.721073\n",
      "1   0.779923  0.869440  0.822252  0.952233  0.694687  0.796321\n",
      "2   0.703704  0.827982  0.760801  0.958614  0.596327  0.741238\n",
      "3   0.598131  0.407643  0.484848  0.975205  0.260779  0.481754\n",
      "4   0.000000  0.000000  0.000000  0.996171  0.003829  0.000000\n",
      "5   0.612046  0.519159  0.561789  0.803464  0.434431  0.438668\n",
      "6   0.676864  0.696850  0.686712  0.941112  0.499750  0.654306\n",
      "7   0.732057  0.517241  0.606181  0.818778  0.508824  0.505515\n",
      "8   0.907022  0.978594  0.941450  0.894257  0.906202  0.438327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data-imperial/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data-imperial/lib/python3.9/site-packages/sklearn/metrics/_classification.py:873: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkiatann\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.0 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f908b16b",
   "metadata": {},
   "source": [
    "## Epoch 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b3fe03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data-imperial/lib/python3.9/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448238472/work/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2743' max='2743' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2743/2743 13:38]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3783, 294, 4624, 164, 4903, 146, 5261, 67, 5460, 4, 3564, 590, 4809, 168, 3426, 580, 395, 325]\n",
      "[306, 1102, 120, 577, 83, 353, 73, 84, 16, 5, 542, 789, 147, 361, 509, 970, 286, 4479]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkiatann\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.0 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.11.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">bigbird_ml_classification_test</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/kiatann/huggingface\" target=\"_blank\">https://wandb.ai/kiatann/huggingface</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/kiatann/huggingface/runs/2l4f26re\" target=\"_blank\">https://wandb.ai/kiatann/huggingface/runs/2l4f26re</a><br/>\n",
       "                Run data is saved locally in <code>/data-imperial/wandb/run-20210824_142627-2l4f26re</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.20496368408203125,\n",
       " 'eval_accuracy': 0.4472196900638104,\n",
       " 'eval_f1': 0.7984294759274478,\n",
       " 'eval_precision': 0.7904147591073108,\n",
       " 'eval_recall': 0.8072579152008887,\n",
       " 'eval_auprc': 0.7158517737385894,\n",
       " 'eval_runtime': 818.7782,\n",
       " 'eval_samples_per_second': 6.699,\n",
       " 'eval_steps_per_second': 3.35}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e17daff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data-imperial/lib/python3.9/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448238472/work/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2743' max='2743' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2743/2743 13:37]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3783  294]\n",
      " [ 306 1102]]\n",
      "[[4624  164]\n",
      " [ 120  577]]\n",
      "[[4903  146]\n",
      " [  83  353]]\n",
      "[[5261   67]\n",
      " [  73   84]]\n",
      "[[5460    4]\n",
      " [  16    5]]\n",
      "[[3564  590]\n",
      " [ 542  789]]\n",
      "[[4809  168]\n",
      " [ 147  361]]\n",
      "[[3426  580]\n",
      " [ 509  970]]\n",
      "[[ 395  325]\n",
      " [ 286 4479]]\n",
      "   precision    recall        f1       acc     auprc       mcc\n",
      "0   0.789398  0.782670  0.786020  0.890611  0.673627  0.712558\n",
      "1   0.778677  0.827834  0.802503  0.948222  0.666493  0.773221\n",
      "2   0.707415  0.809633  0.755080  0.958250  0.587879  0.734366\n",
      "3   0.556291  0.535032  0.545455  0.974476  0.310943  0.532436\n",
      "4   0.555556  0.238095  0.333333  0.996354  0.135192  0.362181\n",
      "5   0.572154  0.592787  0.582288  0.793619  0.437980  0.445422\n",
      "6   0.682420  0.710630  0.696239  0.942571  0.511748  0.664707\n",
      "7   0.625806  0.655849  0.640475  0.801459  0.503233  0.503707\n",
      "8   0.932348  0.939979  0.936148  0.888605  0.928530  0.500342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkiatann\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.0 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.11.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">bigbird_ml_classification_test</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/kiatann/huggingface\" target=\"_blank\">https://wandb.ai/kiatann/huggingface</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/kiatann/huggingface/runs/3nt5y1rk\" target=\"_blank\">https://wandb.ai/kiatann/huggingface/runs/3nt5y1rk</a><br/>\n",
       "                Run data is saved locally in <code>/data-imperial/wandb/run-20210824_144601-3nt5y1rk</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.20496368408203125,\n",
       " 'eval_accuracy': 0.8886052871467639,\n",
       " 'eval_f1': 0.9361479778451248,\n",
       " 'eval_precision': 0.9323480432972523,\n",
       " 'eval_recall': 0.9399790136411332,\n",
       " 'eval_auprc': 0.9285298001252001,\n",
       " 'eval_runtime': 818.4317,\n",
       " 'eval_samples_per_second': 6.702,\n",
       " 'eval_steps_per_second': 3.352}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
